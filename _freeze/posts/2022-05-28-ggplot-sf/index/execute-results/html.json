{
  "hash": "91506c33a85607ebcd29ed751d83c0af",
  "result": {
    "markdown": "---\ntitle: \"How long do maps on ggplot facets take?\"\nauthor: H. Sherry Zhang\ndate: '2022-05-27'\nslug: []\nimage: firstpic.png\ncategories:\n  - data visualisation\n  - teaching\n  - spatial data\ntags:\n  - R\n  - teaching\n  - data visualisation\nsubtitle: ''\nsummary: ''\nlastmod: '2022-05-28T22:49:21+10:00'\nfeatured: no\n---\n\n\n\n\nIf you're a ggplot user, making faceted plots must be a tool in your belt. If you happen to do some spatial analysis, you would be familiar with maps. Today, I will show you my surprise findings about the rendering time to make faceted maps. \n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nThis example comes from [Chapter 7](https://www.paulamoraga.com/book-geospatial/sec-arealdataexamplest.html) of Paula Moraga's book *Geospatial Health Data: Modeling and Visualization with R-INLA and Shiny* and I have simplified it for this demonstration. In essence, there are two datasets: \n\n1. Map data (`ohio`) with 88 Ohio counties in an `sf` object: \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 88 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -84.8203 ymin: 38.40342 xmax: -80.5182 ymax: 42.32713\nGeodetic CRS:  NAD83\n# A tibble: 88 × 2\n   NAME                                                                 geometry\n   <chr>                                                           <POLYGON [°]>\n 1 Auglaize   ((-84.13476 40.65755, -84.13467 40.65755, -84.13405 40.65753, -84…\n 2 Crawford   ((-82.77258 40.99589, -82.77258 40.99588, -82.77168 40.99588, -82…\n 3 Montgomery ((-84.06231 39.8366, -84.06301 39.83665, -84.06501 39.83677, -84.…\n 4 Guernsey   ((-81.22986 40.06315, -81.22987 40.06308, -81.22992 40.06119, -81…\n 5 Clark      ((-83.83875 39.8233, -83.83889 39.82335, -83.83904 39.82339, -83.…\n 6 Gallia     ((-82.18737 38.72608, -82.18727 38.72558, -82.18707 38.72488, -82…\n 7 Fairfield  ((-82.82307 39.80773, -82.82307 39.8078, -82.82305 39.80801, -82.…\n 8 Darke      ((-84.43157 40.15801, -84.43148 40.15487, -84.43148 40.1542, -84.…\n 9 Monroe     ((-81.22569 39.57838, -81.24065 39.57883, -81.2413 39.57885, -81.…\n10 Portage    ((-81.3184 40.98861, -81.31892 40.98862, -81.31927 40.98862, -81.…\n# … with 78 more rows\n```\n:::\n:::\n\n\n2. Lung cancer data (`sir`) with standardized incidence ratios (SIRs) calculated for each county across 21 years (1968 - 1988):\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,848 × 3\n   county  year   SIR\n   <chr>  <dbl> <dbl>\n 1 Adams   1968 0.725\n 2 Adams   1969 0.588\n 3 Adams   1970 1.03 \n 4 Adams   1971 0.654\n 5 Adams   1972 1.05 \n 6 Adams   1973 0.693\n 7 Adams   1974 1.15 \n 8 Adams   1975 1.17 \n 9 Adams   1976 0.936\n10 Adams   1977 0.644\n# … with 1,838 more rows\n```\n:::\n:::\n\n\nThe details on calculating SIR is not the focus of this post and Section [7.1](https://www.paulamoraga.com/book-geospatial/sec-arealdataexamplest.html#sec-arealdataexamplest) to [7.2](https://www.paulamoraga.com/book-geospatial/sec-arealdataexamplest.html#data-preparation-1) of Paula's book has detailed all the steps. Here I attach the script to generate these two data sets in case you would like to give it a spin:\n\n<details><summary>script</summary>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#remotes::install_github(\"Paula-Moraga/SpatialEpiApp\")\nlibrary(SpatialEpiApp)\nlibrary(SpatialEpi)\nlibrary(tidyverse)\nlibrary(sf)\n\n# ohio map data\nohio <- read_sf(system.file(\"SpatialEpiApp/data/Ohio/fe_2007_39_county/fe_2007_39_county.shp\", \n                           package = \"SpatialEpiApp\")) %>% \n  select(NAME, geometry)\n\n# sir case data\nraw <- read_csv(system.file(\"SpatialEpiApp/data/Ohio/dataohiocomplete.csv\", \n                    package = \"SpatialEpiApp\"))\n\ndt <- raw %>% arrange(county, year, gender, race) \nres <- dt %>% \n  group_by(NAME, year) %>% \n  summarise(Y = sum(y)) %>% \n  ungroup()\n\nn_strata <- 4\nE <- expected(population = dt$n, cases = dt$y, n.strata = n_strata)\nnyears <- length(unique(raw$year))\ncountiesE <- rep(unique(raw$NAME), each = nyears)\n\nncounties <- length(unique(raw$NAME))\nyearsE <- rep(unique(raw$year), time = ncounties)\n\nsir <- tibble(county = countiesE, year = yearsE, E = E) %>% \n  left_join(res, by = c(\"county\" = \"NAME\", \"year\")) %>% \n  mutate(SIR = Y/E) %>% \n  select(county, year, SIR)\n```\n:::\n\n\n</details>\n\nWhat we would like to do here is to show the SIR values of each county on the map across years. This would require us to join the two datasets, supply the combined data into ggplot, plot the underlying map, fill the county polygon with `SIR`,  make facets with `year`, and lastly tweak the theme and the fill scale. Let's give this plot a name, say `target`: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncombined <- ohio %>% \n  left_join(sir, by = c(\"NAME\" = \"county\"))\n\ntarget <- combined %>% \n  ggplot() + \n  geom_sf(aes(fill = SIR)) +\n  facet_wrap(~year, dir = \"h\", ncol = 7) +\n  ggtitle(\"SIR\") + \n  theme_bw() +\n  theme(\n    axis.text.x = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks = element_blank()\n  ) +\n  scale_fill_gradient2(\n    midpoint = 1, low = \"blue\", mid = \"white\", high = \"red\"\n  )\n\ntarget\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nEasy peasy. \n\nBut, have you thought about **how long it would take to provide this plot to you?**\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nLet me show you some components of this plot as benchmarks on the timing, here I have: \n\n  1) `P0`: a single map object (left): **0.806 secs**\n  \n  2) `P1`: a single year (1968) with SIR filled (mid): **0.902 secs**, and\n  \n  3) `P2`: two years (1968 & 1969) with SIR filled in facets (right): **1.638 secs**\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n**Okay, now it is your time to make a guess:** \n\n - ~1 or 2 seconds? Ideally if the same map is rendered in parallel across all the facets, the increment of time would be marginal. \n \n - ~16 seconds? The increment of rendering another facet from 2) to 3) is 0.736 (1.638-0.902) seconds.  Projecting that into 20 more facets will give us: 0.902 + (1.638-0.902) * 20 = 16.358 seconds. \n \n - 30 seconds, 40 seconds, 1 minute? I don't know.\n \n### Let's reveal the answer\n\nThere are different ways to check the execution time of a command and here we use `ggplot2::benchplot()`, which breaks down the creation time by constructing, building, rendering, and drawing: \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\nfunction (x) \n{\n    x <- enquo(x)\n    construct <- system.time(x <- eval_tidy(x))\n    if (!inherits(x, \"ggplot\")) {\n        cli::cli_abort(\"{.arg x} must be a {.cls ggplot} object\")\n    }\n    build <- system.time(data <- ggplot_build(x))\n    render <- system.time(grob <- ggplot_gtable(data))\n    draw <- system.time(grid.draw(grob))\n    times <- rbind(construct, build, render, draw)[, 1:3]\n    times <- rbind(times, colSums(times))\n    vec_cbind(step = c(\"construct\", \"build\", \"render\", \"draw\", \n        \"TOTAL\"), mat_2_df(times))\n}\n<bytecode: 0x5613879a61e8>\n<environment: namespace:ggplot2>\n```\n:::\n:::\n\n\nReady for the answer? Here you go: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbenchplot(target)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n       step user.self sys.self elapsed\n1 construct     0.000    0.000   0.000\n2     build     1.289    0.050   1.336\n3    render     0.707    0.055   0.774\n4      draw    25.914    0.067  25.975\n5     TOTAL    27.910    0.172  28.085\n```\n:::\n:::\n\n\nWOW, I did not expect it to take 28.085 seconds to get my plot! \n\n### How come it takes that long? \n\nWe can take a look at the time decomposition of our target plot construction along with the three benchmark plots. This would tell us at which stage our target plot takes the longest: \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=960}\n:::\n:::\n\n\nHere `p0` to `p2` are the three benchmark plots and `p21` is the target plot (since it has 21 facets). Notice the y-axis is the **square root** of elapsed time and the text on each bar is the **actual** elapsed time. \n\nBuilding and rendering times look fine, but our target plot is taking a considerably large amount of time in the **drawing**. Looking back into `benchplot()`, the drawing time is calculated as the time of `grid.draw()` drawing the grob: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndraw <- system.time(grid.draw(grob))\n```\n:::\n\n\nWe could also do an experiment to progressively add facets to see how the drawing time changes as there are more facets. Here I start with `p1` containing only year 1968 and `p2` containing year 1968 & 1969, and add one more year at a time till `p21`, which contains all the 21 years from 1968 to 1988. Here is the script I used to make the simulation: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncombined <- ohio %>% left_join(sir, by = c(\"NAME\" = \"county\")) \n\nmake_plot <- function(data){\n  data %>% \n    ggplot() + \n    geom_sf(aes(fill = SIR)) + \n    theme_bw() +\n    facet_wrap(~year, dir = \"h\", ncol = 7) +\n    theme(\n      axis.text.x = element_blank(),\n      axis.text.y = element_blank(),\n      axis.ticks = element_blank(),\n    )  + \n    scale_fill_gradient2(\n      limits = c(0, range(combined$SIR)[2]),\n      midpoint = 1, low = \"blue\", mid = \"white\", high = \"red\", \n    )\n}\n\nbench_plot <- function(data){\n  p <- make_plot(data)\n  benchplot(p)\n}\n\ntime_all <- map_dfr(year, function(y){\n    dt <- combined %>% filter(year <= y)\n    dev.new()\n    out <- dt %>% bench_plot()\n    while (dev.cur()>1) dev.off()\n    return(out)\n}, .id = \"plot\")\n```\n:::\n\n\nNote that the workhorse, `out <- dt %>% bench_plot()`, is wrapped in between `dev.new()` and \n`while (dev.cur()>1) dev.off()` so that a clean canvas is set up before each evaluation and closed after. Now we can plot the result and take a look: \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe three dotted vertical lines are where a new row takes place in the facet. The dashed line connects `p1` and `p2` and shows how the elapsed time would be if a **linear interpolation** between `p1` and `p2` is followed. **Unfortunately, This is not the case from our plot.**\n\nLooking at these points, something weird is going on here: by the end of the first row, the increment from having six facets (`p6`) to seven facets (`p7`) is much larger than those in early plots (`p1` to `p5`). However, the end of the second row tells us something else: the increment from having 13 facets (`p13`) to 14 facets (`p14`) is almost negligible. This is also the case at the end of the third row (`p20` and `p21`)[^1].\n\n[^1]: To make a proper benchmark of time, ideally each plot (`p1` - `p21`) should be evaluated repetitively to obtain a distribution of the elapsed time. I set up a script with 50 repetitions and let it run overnight, but what I got next morning was \"RStudio quit unexpectedly\". I suspect there is something going on with opening and closing the graphic devices too many times...\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n### Back to the initial problem\n\nWhile I don't know the answer of why the drawing time with additional facets has such a pattern, what initially annoyed me was it takes much longer than I expected to create the target plot. \n\n**If we only want to cut the run time, there is always the trick of simplifying your map object.** Applying `rmapshaper:: ms_simplify()` on `ohio` will keep 1% of the points in the polygons by default and it can instantly bring the rendering time of our target plot down to 1.107 seconds: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nohio2 <- ohio %>% rmapshaper::ms_simplify()\ncombined2 <- ohio2 %>% left_join(sir, by = c(\"NAME\" = \"county\"))\ntarget2 <- combined2 %>% make_plot()\nbenchplot(target2)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n       step user.self sys.self elapsed\n1 construct     0.000        0   0.000\n2     build     0.550        0   0.550\n3    render     0.348        0   0.348\n4      draw     0.209        0   0.209\n5     TOTAL     1.107        0   1.107\n```\n:::\n:::\n\n\nAnd how does the plot look like after the simplification? \n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAt least I can't tell the difference between this and the original plot. \n\n**Possibly, you're as surprised as I was when first seeing how long it takes to render our facetted map. We find that it is the drawing time that takes the majority of the time to create the plot and the time required to draw more facet is not a linear increase of the initial two facets.** However, technically, we didn't answer the question of why it takes that long to render the target plot or what `grid.draw()` is doing when plotting the facets. But even if we can't answer it, a fast rendering is still available if we **remember map simplification. Map simplication is a simple strategy to handle plotting spatial data efficiently, and effectively.** \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}